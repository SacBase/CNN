module cnn_tc;


use CommandLine: all;
use MathArray: all;
use Structures: all;
use StdIO: all;

export all;

#define MBI 1

inline
float[*] averageOuter( float[+] array)
{
  return { iv -> sum ({ [i] -> array[[i]++iv] | [i] < take( [1], shape( array)) })
           | iv < drop([1], shape( array)) } / tof( shape( array)[0]);
}

inline
float average( float[*] array)
{
   return sum( array) / tof( prod( shape( array)));
}

int MaxPos( float[10,1,1,1,1] output)
{
   max = output[[0,0,0,0,0]];
   res = 0;
   for( i=0; i<10; i++) 
      if( output[[i,0,0,0,0]] > max) {
        max = output[[i,0,0,0,0]];
        res = i;
      }
   return res;
}

//------------------------------------------------------------------------------
// Convolution function
//------------------------------------------------------------------------------

inline
float[*] MultiConv( float[*] in, float[*] weights, float[*] bias)
{
  shp_act_map = (shape(in) - take( -[dim(in)], shape(weights))) + 1;
  shp_maps = drop( -[dim(in)], shape(weights));

  return { iv -> Convolve (in, weights[iv]) + bias[iv] | iv <shp_maps};
}


inline
float[*] Convolve( float[*] in, float[*] weights)
{
   shp = shape( in) - shape(weights) + 1;

   return { iv -> sum( { ov -> in[iv+ov] * weights[ov] }) | iv <shp};
}

float[*], float[*], float[*]
BackMultiConv( float[*] d_out, float[*] weights, float[*] in, float[*] bias)
{
  shp_act_map = take( -[dim(in)], shape(weights));
  shp_maps = drop( -[dim(in)], shape(weights));

#if 1
  d_in = { iv -> sum ( { ov -> with {
                              ( max( 0*shp_act_map, iv - take( -[dim(in)], shape(d_out)) + 1)
                                <= ov2 < min( shp_act_map, iv+1 )) : weights[ov ++ ov2] * d_out[ov ++ (iv-ov2)];
                              } : fold( +, 0f);
                         ov -> 0f | ov < shp_maps } );
           iv -> 0f | iv < shape(in) };
#else
  d_in = { iv -> sum ( { ov -> sum ( { ov2 -> weights[ov ++ ov2] * d_out[ov ++ (iv-ov2)] 
                                         | max( 0*shp_act_map, iv - take( -[dim(in)], shape(d_out)) + 1) <= ov2;
                                       ov2 -> 0f
                                         | ov2 < min( shp_act_map, iv+1 ) });
                          ov -> 0f | ov < shp_maps});
           iv -> 0f | iv < shape(in) };
#endif

  d_weights = { iv -> BackWeights2( d_out[iv], weights[iv], in) | iv < shp_maps};

  d_bias = { iv -> BackBias( d_out[iv]) | iv <shp_maps};

  return ( d_in, d_weights, d_bias);
}

inline
float[*] BackWeights2( float[*] d_out, float[*] weights, float[*] in)
{
  return { ov -> sum ({ iv -> in[ iv+ov] * d_out[iv]}) | ov < shape (weights)};
}

inline
float[*] BackBias( float[*] d_out)
{
  return sum( d_out);
}

//------------------------------------------------------------------------------
// Activation functions
//------------------------------------------------------------------------------

inline
float[*] Logistic( float[*] in)
{
  return 1f/(1f + exp( -(in)));
}

inline
float[*] BackLogistic( float[*] d_out, float[*] out)
{
  return d_out * out * (1f - out);
}

//------------------------------------------------------------------------------
// Pooling functions
//------------------------------------------------------------------------------


inline
float[*] AveragePool( float[*] in, int[.] filter)
{
  ones = genarray( [dim( in)], 1);
  filter = drop( shape( filter), ones) ++ filter;
  shp = shape( in) / filter;

  return { iv -> average( { ov -> in[iv*filter+ov] | ov < filter}) | iv <shp};
}

inline
float[*] BackAveragePool( float[*] d_out, int[.] filter )
{
  ones = genarray( [dim( d_out)], 1);
  filter = drop( shape( filter), ones) ++ filter;
  shp = shape( d_out) * filter;

  return { iv -> d_out[iv/filter] / tof( prod( filter)) | iv <shp};
}

//------------------------------------------------------------------------------
// Error functions
//------------------------------------------------------------------------------

inline
float MeanSquaredError( float[*] result, float[*] labels)
{
  return sum ( 0.5f * ( labels - result) * ( labels - result) );
}


//------------------------------------------------------------------------------
// Commandline functions
//------------------------------------------------------------------------------

int, int, int, int, float
CnnReadParameters( int epochs, int batchsize, int trainings, int tests, float rate)
{
   if( (argc() == 2) && (strcmp( argv(1), "-h") == 0 )) {
      printf( "%s -mt <n> -e <epocs> -b <batchsize> -tr <training-items>"
              " -te <test-items> -r <rate>\n", argv(0));
      epochs = 0;
      batchsize = 0;
      trainings = 0;
      tests = 0;
      rate = 0f;
   } else {
      if( (argc() >1)  && ( strcmp( argv(1), "-mt") == 0 )) {
        off = 2;
      } else {
        off = 0;
      }
      while( argc() > off+1) {
         if( strcmp( argv(off+1), "-e") == 0 ) {
            epochs = toi( argv( off+2));
         } else if( strcmp( argv(off+1), "-b") == 0 ) {
            batchsize = toi( argv( off+2));
         } else if( strcmp( argv(off+1), "-tr") == 0 ) {
            trainings = toi( argv( off+2));
         } else if( strcmp( argv(off+1), "-te") == 0 ) {
            tests = toi( argv( off+2));
         } else if( strcmp( argv(off+1), "-r") == 0 ) {
            rate = tof( argv( off+2));
         } else {
            printf( "ignoring non-recognised parameter %s!\n", argv(off+1));
            off --;
         }
         off += 2;
      }
   }

   return (epochs, batchsize, trainings, tests, rate);
}
