import cnn: all;
import convolution: all;
import activation: all;
import pooling: all;

use Benchmarking: all;
use MathArray: all;
use Structures: all;
use StdIO: all;

#define CATEGORIES 10

//specialize float[*] MultiConv( float[28,28] in, float[6,5,5] weights, float[6] bias);
//specialize float[*] MultiConv( float[6,12,12] in, float[12,6,5,5] weights, float[12] bias);
//specialize float[*] MultiConv( float[12,1,4,4] in, float[CATEGORIES,12,1,4,4] weights, float[CATEGORIES] bias);

specialize float[*], float[*], float[*] BackMultiConv( float[6,24,24] d_out, float[6,5,5] weights, float[28,28] in, float[6] bias);
specialize float[*], float[*], float[*] BackMultiConv( float[12,1,8,8] d_out, float[12,6,5,5] weights, float[6,12,12] in, float[12] bias);
specialize float[*], float[*], float[*] BackMultiConv( float[CATEGORIES,1,1,1,1] d_out, float[CATEGORIES,12,1,4,4] weights, float[12,1,4,4] in, float[CATEGORIES] bias);

//specialize float[*] BackIn( float[24,24] d_out, float[5,5] weights, float[28,28] in);
//specialize float[*] BackIn( float[1,8,8] d_out, float[6,5,5] weights, float[6,12,12] in);
//specialize float[*] BackIn( float[1,1,1,1] d_out, float[12,1,4,4] weights, float[12,1,4,4] in);

//specialize float[*] BackIn2( float[24,24] d_out, float[5,5] weights, float[28,28] in);
//specialize float[*] BackIn2( float[1,8,8] d_out, float[6,5,5] weights, float[6,12,12] in);
//specialize float[*] BackIn2( float[1,1,1,1] d_out, float[12,1,4,4] weights, float[12,1,4,4] in);

//specialize float[*] BackWeights( float[24,24] d_out, float[5,5] weights, float[28,28] in);
//specialize float[*] BackWeights( float[1,8,8] d_out, float[6,5,5] weights, float[6,12,12] in);
//specialize float[*] BackWeights( float[1,1,1,1] d_out, float[12,1,4,4] weights, float[12,1,4,4] in);

//specialize float[*] BackWeights2( float[24,24] d_out, float[5,5] weights, float[28,28] in);
//specialize float[*] BackWeights2( float[1,8,8] d_out, float[6,5,5] weights, float[6,12,12] in);
//specialize float[*] BackWeights2( float[1,1,1,1] d_out, float[12,1,4,4] weights, float[12,1,4,4] in);

//------------------------------------------------------------------------------
// Network Construction
//------------------------------------------------------------------------------

float[6,5,5], float[6], float[12,6,5,5], float[12], float[CATEGORIES,12,1,4,4], float[CATEGORIES], float
TrainZhang( float[28,28] in, float[6,5,5] k1, float[6] b1,
                             float[12,6,5,5] k2, float[12] b2,
                             float[CATEGORIES,12,1,4,4] fc, float[CATEGORIES] b,
                             float[CATEGORIES,1,1,1,1] target)
{
  float[6,24,24] c1, d_c1;
  float[6,12,12] s1, d_s1;
  float[12,1,8,8] c2, d_c2;
  float[12,1,4,4] s2, d_s2;
  float[CATEGORIES,1,1,1,1] out, d_out;

  c1 = Logistic( MultiConv( in, k1, b1 ));
  s1 = AveragePool( c1, [2,2]);
  c2 = Logistic( MultiConv( s1, k2, b2));
  s2 = AveragePool( c2, [2,2]);
  out = Logistic( MultiConv( s2, fc, b));

  d_out = out - target;
  error = MeanSquaredError( out, target);

  d_s2, d_fc, d_b = BackMultiConv( BackLogistic( d_out, out), fc, s2, b);
  d_c2 = BackAveragePool( d_s2, [2,2]);
  d_s1, d_k2, d_b2 = BackMultiConv( BackLogistic( d_c2, c2), k2, s1, b2);
  d_c1 = BackAveragePool( d_s1, [2,2]);
  _, d_k1, d_b1 = BackMultiConv( BackLogistic( d_c1, c1), k1, in, b1);

  return ( d_k1, d_b1, d_k2, d_b2, d_fc, d_b, error);
}

int[.], int[.], int[.], int[.], int[.], int[.], int[.], double
TrainZhangFlop( int[.] in_shp, int[.] k1_shp, int[.] b1_shp,
                             int[.] k2_shp, int[.] b2_shp,
                             int[.] fc_shp, int[.] b_shp,
                             int[.] target_shp)
{
  out1_shp, mc1flops = MultiConvFlop( in_shp, k1_shp, b1_shp);
  c1_shp, log1flops = LogisticFlop( out1_shp);
  s1_shp, ap1flops = AveragePoolFlop( c1_shp, [2,2]);
  out2_shp, mc2flops = MultiConvFlop( s1_shp, k2_shp, b2_shp);
  c2_shp, log2flops = LogisticFlop( out2_shp);
  s2_shp, ap2flops = AveragePoolFlop( c2_shp, [2,2]);
  out3_shp, mc3flops = MultiConvFlop( s2_shp, fc_shp, b_shp);
  out_shp, log3flops = LogisticFlop( out3_shp);

  flops = mc1flops + log1flops + ap1flops
          + mc2flops + log2flops + ap2flops
          + mc3flops + log3flops ;

  flops += tod( prod( out_shp));
  error_shp, msqflops = MeanSquaredErrorFlop( out_shp, target_shp);
  flops += msqflops;

  tmp1_shp, bl1flops = BackLogisticFlop( out_shp, out_shp);
  d_s2_shp, d_fc_shp, d_b_shp, bmc1flops = BackMultiConvFlop( tmp1_shp, fc_shp, s2_shp, b_shp);
  d_c2_shp, bap1flops = BackAveragePoolFlop( d_s2_shp, [2,2]);
  tmp2_shp, bl2flops = BackLogisticFlop( d_c2_shp, c2_shp);
  d_s1_shp, d_k2_shp, d_b2_shp, bmc2flops = BackMultiConvFlop( tmp2_shp, k2_shp, s1_shp, b2_shp);
  d_c1_shp, bap2flops = BackAveragePoolFlop( d_s1_shp, [2,2]);
  tmp3_shp, bl3flops = BackLogisticFlop( d_c1_shp, c1_shp);
  _, d_k1_shp, d_b1_shp, bmc3flops = BackMultiConvFlop( tmp3_shp, k1_shp, in_shp, b1_shp);

  flops += bl1flops + bmc1flops + bap1flops
           + bl2flops + bmc2flops + bap2flops
           + bl3flops + bmc3flops ;

  printf("FLOP DETAIL 1 image:\n");
  printf("----------------------------\n");
  printf("conv 1:     %14s\n", flops2String( mc1flops));
  printf("logistic 1: %14s\n", flops2String( log1flops));
  printf("ave-pool 1: %14s\n", flops2String( ap1flops));
  printf("conv 2:     %14s\n", flops2String( mc2flops));
  printf("logistic 2: %14s\n", flops2String( log2flops));
  printf("ave-pool 2: %14s\n", flops2String( ap2flops));
  printf("conv 3(fc): %14s\n", flops2String( mc3flops));
  printf("logistic 3: %14s\n", flops2String( log3flops));
  printf("----------------------------\n");
  printf("diff:       %14s\n", flops2String( tod( prod( out_shp))));
  printf("mean-sqr:   %14s\n", flops2String( log3flops));
  printf("----------------------------\n");
  printf("b-log 1:    %14s\n", flops2String( bl1flops));
  printf("b-conv 1:   %14s\n", flops2String( bmc1flops));
  printf("b-ave-p 1:  %14s\n", flops2String( bap1flops));
  printf("b-log 2:    %14s\n", flops2String( bl2flops));
  printf("b-conv 2:   %14s\n", flops2String( bmc2flops));
  printf("b-ave-p 2:  %14s\n", flops2String( bap2flops));
  printf("b-log 3:    %14s\n", flops2String( bl3flops));
  printf("b-conv 3:   %14s\n", flops2String( bmc3flops));
  printf("----------------------------\n");
  printf("total:      %14s\n", flops2String( flops));

  return (k1_shp, b1_shp, k2_shp, b2_shp, fc_shp, b_shp, [], flops);
}

float[CATEGORIES,1,1,1,1]
TestZhang(float[28,28] in, float[6,5,5] k1, float[6] b1,
                             float[12,6,5,5] k2, float[12] b2,
                             float[CATEGORIES,12,1,4,4] fc, float[CATEGORIES] b )
{
   c1 = Logistic( MultiConv( in, k1, b1 ));
   s1 = AveragePool( c1, [2,2]);
   c2 = Logistic( MultiConv( s1, k2, b2));
   s2 = AveragePool( c2, [2,2]);
   out = Logistic( MultiConv( s2, fc, b));

   return out;
}

int[.], double TestZhangFlop( int[.] in_shp, int[.] k1_shp, int[.] b1_shp,
                              int[.] k2_shp, int[.] b2_shp,
                              int[.] fc_shp, int[.] b_shp)
{
  out1_shp, mc1flops = MultiConvFlop( in_shp, k1_shp, b1_shp);
  c1_shp, log1flops = LogisticFlop( out1_shp);
  s1_shp, ap1flops = AveragePoolFlop( c1_shp, [2,2]);
  out2_shp, mc2flops = MultiConvFlop( s1_shp, k2_shp, b2_shp);
  c2_shp, log2flops = LogisticFlop( out2_shp);
  s2_shp, ap2flops = AveragePoolFlop( c2_shp, [2,2]);
  out3_shp, mc3flops = MultiConvFlop( s2_shp, fc_shp, b_shp);
  out_shp, log3flops = LogisticFlop( out3_shp);

  flops = mc1flops + log1flops + ap1flops
          + mc2flops + log2flops + ap2flops
          + mc3flops + log3flops ;
  return( out_shp, flops);
}

//------------------------------------------------------------------------------

int main()
{
   
   epochs, batchsize, trainings, tests, rate = CnnReadParameters( 20, 100, 1000, 10000, 0.5f);

   k1 = genarray( [6,5,5], 1f/25f);
   b1 = genarray( [6], 1f/6f);
   k2 = genarray( [12,6,5,5], 1f/150f);
   b2 = genarray( [12], 1f/12f);
   fc = genarray( [CATEGORIES,12,1,4,4], 1f/192f);
   b = genarray( [CATEGORIES], 1f/tof(CATEGORIES));

   printf( "Reading training images ...\n");
   training_images = ( float[60000,28,28]) mnist::ReadImages( "tutorial/train-images.idx3-ubyte");
   printf( "Read %d training images ...\n", shape(training_images)[0]);

   printf( "Reading training labels ...\n");
   training_labels = ( int[60000]) mnist::ReadLabels( CATEGORIES, "tutorial/train-labels.idx1-ubyte");
   printf( "Read %d training labels ...\n", shape(training_labels)[0]);

   printf( "Reading test images ...\n");
   test_images = (float[10000,28,28])mnist::ReadImages( "tutorial/t10k-images.idx3-ubyte");
   printf( "Read %d training images ...\n", shape(test_images)[0]);

   printf( "Reading test labels ...\n");
   test_labels = (int[10000])mnist::ReadLabels( CATEGORIES, "tutorial/t10k-labels.idx1-ubyte");
   printf( "Read %d training labels ...\n", shape(test_labels)[0]);

   printf( "Running Zhang with %d epochs, batchsize %d, %d training images, %d tests, and a rate of %f\n",
           epochs, batchsize, trainings, tests, tod( rate));

   trainings = min( shape(training_images)[0], trainings);
   tests = min( shape(test_images)[0], tests);

   i1 = getInterval( "training", 0);
   i2 = getInterval( "test", 1);
   
   k1_shp, b1_shp, k2_shp, b2_shp, fc_shp, b_shp, err_shp, flops = 
             TrainZhangFlop( shape( training_images[0]), shape(k1), shape(b1),
                             shape(k2), shape(b2),
                             shape(fc), shape(b),
                             [CATEGORIES,1,1,1,1]);

   training_flops = flops * tod(trainings) * tod(epochs);

   printf( "total flops for training %d epochs on %d images: %s\n", epochs, trainings,
            flops2String( training_flops));

   out_shp, flops = TestZhangFlop( shape( training_images[0]), shape(k1), shape(b1),
                             shape(k2), shape(b2),
                             shape(fc), shape(b));

   testing_flops = flops * tod(tests);

   printf( "total flops for testing %d images: %s\n", tests,
            flops2String( testing_flops));


   if (epochs > 0) {
      start( i1);
      for( epoch = 1; epoch <=epochs; epoch++) {
         error = 0d;
         for( i=0; i< trainings/batchsize; i++) { 
            bd_k1, bd_b1, bd_k2, bd_b2, bd_fc, bd_b, berr
               = with {
                    (.<= iv <= .) {
                       in = training_images[i*batchsize+iv];
                       target = genarray([CATEGORIES,1,1,1,1], 0f);
                       target[[training_labels[i*batchsize+iv],0,0,0,0]] = 1f;
                       d_k1, d_b1, d_k2, d_b2, d_fc, d_b, err
                          = TrainZhang( in, k1, b1, k2, b2, fc, b, target);
                    } : (d_k1, d_b1, d_k2, d_b2, d_fc, d_b, err);
                 } : ( genarray([batchsize], k1),
                       genarray([batchsize], b1),
                       genarray([batchsize], k2),
                       genarray([batchsize], b2),
                       genarray([batchsize], fc),
                       genarray([batchsize], b),
                       genarray([batchsize], 0f));
            k1 = k1-rate*averageOuter( bd_k1);
            b1 = b1-rate*averageOuter( bd_b1);
            k2 = k2-rate*averageOuter( bd_k2);
            b2 = b2-rate*averageOuter( bd_b2);
            fc = fc-rate*averageOuter( bd_fc);
            b = b-rate*averageOuter( bd_b);
   
            error += tod(sum(berr));
   
         }
         printf( "The mean error of epoch %d is %f\n",
                 epoch,
                 error / tod( trainings) );
      }
      end( i1);
      printResult( i1);
   
      time, unit_str = returnResultUnit( i1);
      training_flops_sec = training_flops / time;
   
      printf( "flop performance for training %d epochs on %d images: %s/%s\n", epochs, trainings,
               flops2String( training_flops_sec), unit_str);
   
      start( i2);

      out = with {
              (. <= iv <= .) : TestZhang( test_images[iv], k1, b1, k2, b2, fc, b);
            } : genarray( [tests], genarray( [CATEGORIES,1,1,1,1], 0f));

      correct = with {
                  ([0] <= iv < [tests]) : MaxPos( out[iv]) == test_labels[iv] ? 1 : 0;
                } : fold( +, 0);

      error = with {
                  ([0] <= iv < [tests]) {
                    target = genarray([CATEGORIES,1,1,1,1], 0f);
                    target[[test_labels[iv],0,0,0,0]] = 1f;
                  } : tod( MeanSquaredError( out[iv], target));
              } : fold( +, 0d);

      end(i2);

      printf( "%d of %d numbers correctly identified!\n", correct, tests);
      printf( "The mean error of %d tests is %f\n",
              min( shape(test_images)[0], tests),
              error / tod( tests) );
      printResult( i2);

      time, unit_str = returnResultUnit( i2);
      training_flops_sec = testing_flops / time;

      printf( "flop performance for testing %d images: %s/%s\n", tests,
               flops2String( training_flops_sec), unit_str);

   }

   return 0;
}
  


